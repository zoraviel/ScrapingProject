{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modified-ghost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Alabama', '$215')]\n",
      "[('Alaska', '923')]\n",
      "[('Arizona', '278')]\n",
      "[('Arkansas', '204')]\n",
      "[('California', '878')]\n",
      "[('Colorado', '508')]\n",
      "[('Connecticut', '698')]\n",
      "[('Delaware', '338')]\n",
      "[('D.C.', '658')]\n",
      "[('Florida', '303')]\n",
      "[('Georgia', '280')]\n",
      "[('Hawai’i', '610')]\n",
      "[('Idaho', '309')]\n",
      "[('Illinois', '533')]\n",
      "[('Indiana', '288')]\n",
      "[('Iowa', '426')]\n",
      "[('Kansas', '429')]\n",
      "[('Kentucky', '262')]\n",
      "[('Louisiana', '240')]\n",
      "[('Maine', '610')]\n",
      "[('Maryland', '727')]\n",
      "[('Massachusetts', '633')]\n",
      "[('Michigan', '492')]\n",
      "[('Minnesota', '632')]\n",
      "[('Mississippi', '170')]\n",
      "[('Missouri', '292')]\n",
      "[('Montana', '588')]\n",
      "[('Nebraska', '468')]\n",
      "[('Nevada', '386')]\n",
      "[('New Hampshire', '1086')]\n",
      "[('New Jersey', '559')]\n",
      "[('New Mexico', '447')]\n",
      "[('New York', '789')]\n",
      "[('North Carolina', '272')]\n",
      "[('North Dakota', '486')]\n",
      "[('Ohio', '505')]\n",
      "[('Oklahoma', '292')]\n",
      "[('Oregon', '506')]\n",
      "[('Pennsylvania', '421')]\n",
      "[('Rhode Island', '554')]\n",
      "[('South Carolina', '299')]\n",
      "[('South Dakota', '615')]\n",
      "[('Tennessee', '277')]\n",
      "[('Texas', '303')]\n",
      "[('Utah', '498')]\n",
      "[('Vermont', '699')]\n",
      "[('Virginia', '508')]\n",
      "[('Washington', '569')]\n",
      "[('West Virginia', '340')]\n",
      "[('Wisconsin', '653')]\n",
      "[('Wyoming', '712')]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.cbpp.org/research/family-income-support/tanf-benefits-still-too-low-to-help-families-especially-black\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text,'html.parser')\n",
    "for match in soup.findAll('sup'):\n",
    "    match.replace_with('')\n",
    "\n",
    "#open file and make variable \n",
    "csvfile = open('tanf.csv', 'w', newline='', encoding='utf-8')\n",
    "\n",
    "z = csv.writer(csvfile)\n",
    "z.writerow( ['Tanf State Name','Tanf Monthly Benefit', 'Low Cost City & State', ' Median Home Value'] )\n",
    "\n",
    "#now get the specific appendix table, not the first table\n",
    "table = soup.find_all('table')\n",
    "benefits = table[2]\n",
    "rows = benefits.find_all('tr')\n",
    "\n",
    "\n",
    "#try to find the a way to get all of the state names, and the monthly benefits in 2020 \n",
    "for data in rows:\n",
    "    try:\n",
    "        my_list=[]\n",
    "        cells = data.find_all('td')\n",
    "        cellz = cells[0].text,cells[6].text\n",
    "        my_list.append(cellz)\n",
    "        for item in my_list:\n",
    "        # write one row to csv — item MUST BE a LIST\n",
    "            z.writerow(item)\n",
    "            print(my_list)\n",
    "    except:\n",
    "        pass\n",
    "csvfile.close()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "import csv\n",
    "\n",
    "\n",
    "# CHANGE TO YOUR DRIVER PATH\n",
    "driver = webdriver.Chrome(r'C:\\Users\\zorav\\OneDrive\\Documents\\python\\scraping\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "driver.get('https://www.niche.com/places-to-live/search/cities-with-the-lowest-cost-of-living/')\n",
    "page = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list = soup.find_all('li', class_='search-results__list__item')\n",
    "len(city_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = []\n",
    "\n",
    "for city in city_list:\n",
    "    yay = (city.find('a').attrs['href'])\n",
    "    link_list.append(yay)\n",
    "\n",
    "print(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\zorav\\OneDrive\\Documents\\python\\scraping\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "driver.get('https://www.niche.com/places-to-live/search/cities-with-the-lowest-cost-of-living/?page=2')\n",
    "page = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_list = soup.find_all('li', class_='search-results__list__item')\n",
    "len(second_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "for second in second_list:\n",
    "    yep = (second.find('a').attrs['href'])\n",
    "    link_list.append(yep)\n",
    "print(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_info(link_list):\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\zorav\\OneDrive\\Documents\\python\\scraping\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "    driver.get(link_list)\n",
    "    page = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    driver.quit()\n",
    "    csvfile = open('tanf.csv', 'a', newline='', encoding='utf-8')\n",
    "\n",
    "    z = csv.writer(csvfile)\n",
    "\n",
    "    try:\n",
    "        for man in soup.findAll('div', class_='scalar__national__value'):\n",
    "            man.replace_with('')\n",
    "        third_list = []\n",
    "        stuff = soup.find('h1')\n",
    "        city = soup.find_all('li', class_='postcard__attr postcard-fact')\n",
    "        citystate =(stuff.text + ',' + ' ' + city[0].text)\n",
    "        \n",
    "        cash = soup.find_all('div', class_='scalar__value')\n",
    "        medianval = (cash[1].text)\n",
    "        together = citystate,medianval\n",
    "        third_list.append(together)\n",
    "        for now in third_list:\n",
    "            z.writerow(now)\n",
    "        \n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass\n",
    "          \n",
    "for link in link_list:\n",
    "    get_info(link)\n",
    "    \n",
    "\n",
    "csvfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
